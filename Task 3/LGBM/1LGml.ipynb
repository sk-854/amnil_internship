{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ccbfb2-94d8-4287-b265-fdb5a435bf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deepface\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_score, recall_score,ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ebbfe7-dbe7-4495-8dc4-5882c4384e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (1296675, 24)\n",
      "\n",
      "Data types:\n",
      " Unnamed: 0                 int64\n",
      "trans_date_trans_time     object\n",
      "cc_num                     int64\n",
      "merchant                  object\n",
      "category                  object\n",
      "amt                      float64\n",
      "first                     object\n",
      "last                      object\n",
      "gender                    object\n",
      "street                    object\n",
      "city                      object\n",
      "state                     object\n",
      "zip                        int64\n",
      "lat                      float64\n",
      "long                     float64\n",
      "city_pop                   int64\n",
      "job                       object\n",
      "dob                       object\n",
      "trans_num                 object\n",
      "unix_time                  int64\n",
      "merch_lat                float64\n",
      "merch_long               float64\n",
      "is_fraud                   int64\n",
      "merch_zipcode            float64\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      " Unnamed: 0                    0\n",
      "trans_date_trans_time         0\n",
      "cc_num                        0\n",
      "merchant                      0\n",
      "category                      0\n",
      "amt                           0\n",
      "first                         0\n",
      "last                          0\n",
      "gender                        0\n",
      "street                        0\n",
      "city                          0\n",
      "state                         0\n",
      "zip                           0\n",
      "lat                           0\n",
      "long                          0\n",
      "city_pop                      0\n",
      "job                           0\n",
      "dob                           0\n",
      "trans_num                     0\n",
      "unix_time                     0\n",
      "merch_lat                     0\n",
      "merch_long                    0\n",
      "is_fraud                      0\n",
      "merch_zipcode            195973\n",
      "dtype: int64\n",
      "         Unnamed: 0        cc_num           amt           zip           lat  \\\n",
      "count  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \n",
      "mean   6.483370e+05  4.171920e+17  7.035104e+01  4.880067e+04  3.853762e+01   \n",
      "std    3.743180e+05  1.308806e+18  1.603160e+02  2.689322e+04  5.075808e+00   \n",
      "min    0.000000e+00  6.041621e+10  1.000000e+00  1.257000e+03  2.002710e+01   \n",
      "25%    3.241685e+05  1.800429e+14  9.650000e+00  2.623700e+04  3.462050e+01   \n",
      "50%    6.483370e+05  3.521417e+15  4.752000e+01  4.817400e+04  3.935430e+01   \n",
      "75%    9.725055e+05  4.642255e+15  8.314000e+01  7.204200e+04  4.194040e+01   \n",
      "max    1.296674e+06  4.992346e+18  2.894890e+04  9.978300e+04  6.669330e+01   \n",
      "\n",
      "               long      city_pop     unix_time     merch_lat    merch_long  \\\n",
      "count  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \n",
      "mean  -9.022634e+01  8.882444e+04  1.349244e+09  3.853734e+01 -9.022646e+01   \n",
      "std    1.375908e+01  3.019564e+05  1.284128e+07  5.109788e+00  1.377109e+01   \n",
      "min   -1.656723e+02  2.300000e+01  1.325376e+09  1.902779e+01 -1.666712e+02   \n",
      "25%   -9.679800e+01  7.430000e+02  1.338751e+09  3.473357e+01 -9.689728e+01   \n",
      "50%   -8.747690e+01  2.456000e+03  1.349250e+09  3.936568e+01 -8.743839e+01   \n",
      "75%   -8.015800e+01  2.032800e+04  1.359385e+09  4.195716e+01 -8.023680e+01   \n",
      "max   -6.795030e+01  2.906700e+06  1.371817e+09  6.751027e+01 -6.695090e+01   \n",
      "\n",
      "           is_fraud  merch_zipcode  \n",
      "count  1.296675e+06   1.100702e+06  \n",
      "mean   5.788652e-03   4.682575e+04  \n",
      "std    7.586269e-02   2.583400e+04  \n",
      "min    0.000000e+00   1.001000e+03  \n",
      "25%    0.000000e+00   2.511400e+04  \n",
      "50%    0.000000e+00   4.586000e+04  \n",
      "75%    0.000000e+00   6.831900e+04  \n",
      "max    1.000000e+00   9.940300e+04  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1296675 non-null  int64  \n",
      " 1   trans_date_trans_time  1296675 non-null  object \n",
      " 2   cc_num                 1296675 non-null  int64  \n",
      " 3   merchant               1296675 non-null  object \n",
      " 4   category               1296675 non-null  object \n",
      " 5   amt                    1296675 non-null  float64\n",
      " 6   first                  1296675 non-null  object \n",
      " 7   last                   1296675 non-null  object \n",
      " 8   gender                 1296675 non-null  object \n",
      " 9   street                 1296675 non-null  object \n",
      " 10  city                   1296675 non-null  object \n",
      " 11  state                  1296675 non-null  object \n",
      " 12  zip                    1296675 non-null  int64  \n",
      " 13  lat                    1296675 non-null  float64\n",
      " 14  long                   1296675 non-null  float64\n",
      " 15  city_pop               1296675 non-null  int64  \n",
      " 16  job                    1296675 non-null  object \n",
      " 17  dob                    1296675 non-null  object \n",
      " 18  trans_num              1296675 non-null  object \n",
      " 19  unix_time              1296675 non-null  int64  \n",
      " 20  merch_lat              1296675 non-null  float64\n",
      " 21  merch_long             1296675 non-null  float64\n",
      " 22  is_fraud               1296675 non-null  int64  \n",
      " 23  merch_zipcode          1100702 non-null  float64\n",
      "dtypes: float64(6), int64(6), object(12)\n",
      "memory usage: 237.4+ MB\n",
      "Dataset info: None\n",
      "\n",
      "Target distribution:\n",
      " is_fraud\n",
      "0    1289169\n",
      "1       7506\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution (normalized):\n",
      " is_fraud\n",
      "0    0.994211\n",
      "1    0.005789\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Load dataset\n",
    "df = pd.read_csv('carddata.csv')  # Replace with your actual file path\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "print(\"\\nMissing values per column:\\n\", df.isna().sum())\n",
    "print(df.describe())\n",
    "print(\"Dataset info:\", df.info())\n",
    "print(\"\\nTarget distribution:\\n\", df['is_fraud'].value_counts())\n",
    "print(\"\\nTarget distribution (normalized):\\n\", df['is_fraud'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c399c7-67be-407e-921f-128cbe99a3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after removal: Index(['trans_date_trans_time', 'merchant', 'category', 'amt', 'gender',\n",
      "       'state', 'lat', 'long', 'city_pop', 'job', 'unix_time', 'merch_lat',\n",
      "       'merch_long', 'is_fraud', 'merch_zipcode'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   trans_date_trans_time  1296675 non-null  object \n",
      " 1   merchant               1296675 non-null  object \n",
      " 2   category               1296675 non-null  object \n",
      " 3   amt                    1296675 non-null  float64\n",
      " 4   gender                 1296675 non-null  object \n",
      " 5   state                  1296675 non-null  object \n",
      " 6   lat                    1296675 non-null  float64\n",
      " 7   long                   1296675 non-null  float64\n",
      " 8   city_pop               1296675 non-null  int64  \n",
      " 9   job                    1296675 non-null  object \n",
      " 10  unix_time              1296675 non-null  int64  \n",
      " 11  merch_lat              1296675 non-null  float64\n",
      " 12  merch_long             1296675 non-null  float64\n",
      " 13  is_fraud               1296675 non-null  int64  \n",
      " 14  merch_zipcode          1100702 non-null  float64\n",
      "dtypes: float64(6), int64(3), object(6)\n",
      "memory usage: 148.4+ MB\n",
      "Dataset info: None\n"
     ]
    }
   ],
   "source": [
    "#Droppping unnecessary columns\n",
    "cols_to_drop = ['Unnamed: 0', 'cc_num', 'first', 'last', 'street', 'city', 'zip', 'dob', 'trans_num']\n",
    "df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "print(\"Columns after removal:\", df.columns)\n",
    "print(\"Dataset info:\", df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035c2ec3-96ae-4468-af35-c121544b2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values\n",
    "df['merch_zipcode'] = df['merch_zipcode'].fillna(df['merch_zipcode'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "681ab4a9-0ab5-4f45-8b1c-a5d37540c202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    trans_date_trans_time  trans_hour trans_time_of_day\n",
      "0     2019-01-01 00:00:18           0             night\n",
      "1     2019-01-01 00:00:44           0             night\n",
      "2     2019-01-01 00:00:51           0             night\n",
      "3     2019-01-01 00:01:16           0             night\n",
      "4     2019-01-01 00:03:06           0             night\n",
      "..                    ...         ...               ...\n",
      "195   2019-01-01 02:23:41           2             night\n",
      "196   2019-01-01 02:26:14           2             night\n",
      "197   2019-01-01 02:26:16           2             night\n",
      "198   2019-01-01 02:27:58           2             night\n",
      "199   2019-01-01 02:28:24           2             night\n",
      "\n",
      "[200 rows x 3 columns]\n",
      "amt_bin\n",
      "low          324325\n",
      "high         324151\n",
      "very_high    324112\n",
      "medium       324087\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering(extracting time of the day)\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['trans_hour'] = df['trans_date_trans_time'].dt.hour\n",
    "\n",
    "def time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'day'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "df['trans_time_of_day'] = df['trans_hour'].apply(time_of_day)\n",
    "df['trans_time_of_day'] = df['trans_time_of_day'].astype('category')\n",
    "print(df[['trans_date_trans_time', 'trans_hour', 'trans_time_of_day']].head(200))\n",
    "\n",
    "df['amt_bin'] = pd.qcut(df['amt'], 4, labels=['low', 'medium', 'high', 'very_high'])\n",
    "print(df['amt_bin'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00817fd6-697e-4b75-bee7-be7cf5bc1758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_fraud\n",
      "0    92494\n",
      "1     7506\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Sampling only 100k rows\n",
    "fraud_df = df[df['is_fraud'] == 1]\n",
    "nonfraud_df = df[df['is_fraud'] == 0]\n",
    "n_nonfraud = 100000 - len(fraud_df)\n",
    "nonfraud_sampled = nonfraud_df.sample(n=n_nonfraud, random_state=42)\n",
    "df_small = pd.concat([fraud_df, nonfraud_sampled])\n",
    "df_small = df_small.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(df_small['is_fraud'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4022077-787b-4d0f-84ba-fa744b34718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing features and target\n",
    "y = df_small['is_fraud']\n",
    "X = df_small.drop(columns=['is_fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a27b3b-6d9c-4e1d-8b8f-566e121578b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (80000, 16)\n",
      "Test size: (20000, 16)\n",
      "Fraud distribution in train:\n",
      " is_fraud\n",
      "0    73995\n",
      "1     6005\n",
      "Name: count, dtype: int64\n",
      "Fraud distribution in test:\n",
      " is_fraud\n",
      "0    18499\n",
      "1     1501\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Train/test splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train = X_train.drop(columns=['trans_date_trans_time'])\n",
    "X_test = X_test.drop(columns=['trans_date_trans_time'])\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)\n",
    "print(\"Fraud distribution in train:\\n\", y_train.value_counts())\n",
    "print(\"Fraud distribution in test:\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40631bf3-9192-4507-8643-361021b179dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling categorical features\n",
    "categorical_cols = ['merchant', 'category', 'gender', 'state', 'job', 'trans_time_of_day', 'amt_bin']\n",
    "cat_features_indices = [X_train.columns.get_loc(col) for col in categorical_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28183540-4e87-4355-93dc-2f96eeddeae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTENC, class distribution:\n",
      " is_fraud\n",
      "0    73995\n",
      "1    73995\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#BAlancing with SMOTENC\n",
    "smote_nc = SMOTENC(categorical_features=cat_features_indices, random_state=42)\n",
    "X_train_res, y_train_res = smote_nc.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTENC, class distribution:\\n\", y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "382d2667-b007-475d-a0c5-9852eef927ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting categorical columns to category dtype\n",
    "for col in categorical_cols:\n",
    "    X_train_res[col] = X_train_res[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e400197-e457-4754-9e91-8d8cd0c2cbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/05 18:22:41 INFO mlflow.tracking.fluent: Experiment with name 'Fraud_Detection_Models' does not exist. Creating a new experiment.\n",
      "2025/10/05 18:22:41 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 73995, number of negative: 73995\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3268\n",
      "[LightGBM] [Info] Number of data points in the train set: 147990, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training LightGBM model\n",
    "#Set mlflow experiment\n",
    "mlflow.set_experiment(\"Fraud_Detection_Models\")\n",
    "with mlflow.start_run(run_name=\"LGBM-Model\"):\n",
    "    model = LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=-1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    ")\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Log parameters\n",
    "mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "mlflow.log_param(\"n_estimators\", 500)\n",
    "mlflow.log_param(\"learning_rate\", 0.05)\n",
    "mlflow.log_param(\"max_depth\", -1)\n",
    "mlflow.log_param(\"random_state\", 42)\n",
    "mlflow.log_param(\"n_jobs\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d412f8e-3298-4ab2-b5fd-378dbd3dfe27",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "020457ea-d377-42ff-ba29-254dff585ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18499\n",
      "           1       0.88      0.86      0.87      1501\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.93      0.93      0.93     20000\n",
      "weighted avg       0.98      0.98      0.98     20000\n",
      "\n",
      "ROC AUC Score: 0.9912063957649871\n",
      "Precision: 0.8769438810006761\n",
      "Recall: 0.8640906062624917\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "mlflow.log_metric(\"precision\", precision)\n",
    "mlflow.log_metric(\"recall\", recall)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "    \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "plt.savefig('confusion_matrix_lgbm.png')\n",
    "mlflow.log_artifact('confusion_matrix_lgbm.png')\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae45c1fa-667c-4359-ab64-1ae670914896",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Feature Importance\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure()\n",
    "plt.title(\"Feature Importances (LGBM)\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
    "plt.savefig('feature_importance_lgbm.png')\n",
    "mlflow.log_artifact('feature_importance_lgbm.png')\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdf33615-e631-49f5-9961-0d8f4be98edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deepface\\lib\\site-packages\\shap\\explainers\\_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "  warnings.warn(\n",
      "2025/10/05 18:42:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/05 18:42:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x1cd34ca25f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SHAP Explanations\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.savefig('shap_bar_lgbm.png')\n",
    "mlflow.log_artifact('shap_bar_lgbm.png')\n",
    "plt.close()\n",
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.savefig('shap_summary_lgbm.png')\n",
    "mlflow.log_artifact('shap_summary_lgbm.png')\n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Log model\n",
    "mlflow.lightgbm.log_model(model, \"lgbm_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee6d4e58-2eb4-45d6-8265-7c416f8e578d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 0, Predicted: 0\n",
      "Actual: 0, Predicted: 0\n",
      "Actual: 0, Predicted: 0\n",
      "Actual: 0, Predicted: 0\n",
      "Actual: 0, Predicted: 0\n",
      "Actual: 0, Predicted: 0\n",
      "Actual: 0, Predicted: 0\n",
      "Actual: 0, Predicted: 0\n",
      "Actual: 0, Predicted: 0\n",
      "Actual: 0, Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 16: Print 10 sample predictions\n",
    "#sample_indices = random.sample(range(len(X_test)), 10)\n",
    "#for i in sample_indices:\n",
    "#    print(f\"Actual: {y_test.iloc[i]}, Predicted: {y_pred[i]}\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5e2b1-9fcd-4121-85ea-1d35fccbf234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea67b4b-28a8-45f8-890b-035dba0359e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27535c7-f08f-4794-a51d-9463555c1608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f58ef-c2f1-42d8-98b6-5f78d87fcaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48fa5f0-329c-4669-b7f6-92fb0783bf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2055d-d62d-40b6-bfdb-0890f8bd96b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepface)",
   "language": "python",
   "name": "deepface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
